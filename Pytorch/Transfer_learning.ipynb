{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1071eceb",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sahilmaniyar888/Neural-Network-from-Scratch/blob/main/Pytorch/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056a7dd",
   "metadata": {},
   "source": [
    "# Transfer Learning and PreTrained Models\n",
    "### AlexNet on Cats vs Dogs (PyTorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3cb32",
   "metadata": {},
   "source": [
    "## 1) Imports\n",
    "Brief setup imports for model building, data loading, and training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976d432",
   "metadata": {},
   "source": [
    "## 2) Dataset and Transforms\n",
    "Create ImageNet-style transforms, load dataset, and split train/validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto path selection for local vs Google Colab\n",
    "if \"COLAB_RELEASE_TAG\" in os.environ:\n",
    "    PATH_TO_DATA = \"/content/Neural-Network-from-Scratch/data/dogsvscats/\"\n",
    "else:\n",
    "    PATH_TO_DATA = \"../../data/dogsvscats/\"\n",
    "\n",
    "normalizer = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalizer,\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(PATH_TO_DATA, transform=train_transforms)\n",
    "\n",
    "train_samples = int(0.9 * len(dataset))\n",
    "val_samples = len(dataset) - train_samples\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, lengths=[train_samples, val_samples])\n",
    "\n",
    "print(f\"Data Path: {PATH_TO_DATA}\")\n",
    "print(f\"Total: {len(dataset)} | Train: {len(train_dataset)} | Val: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59230e7",
   "metadata": {},
   "source": [
    "## 3) Load AlexNet and Inspect\n",
    "Load architecture and inspect key layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a04b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2faeaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first classifier linear layer\n",
    "print(model.classifier[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc44b1",
   "metadata": {},
   "source": [
    "## 4) Update Output Layer for Cats vs Dogs\n",
    "Replace final layer to output 2 classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet()\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf08695",
   "metadata": {},
   "source": [
    "## 5) Sanity Check Forward Pass\n",
    "Pass random image batch and check output shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data = torch.rand(16, 3, 224, 224)\n",
    "model_output = model(rand_data)\n",
    "print(model_output.shape)  # expected: [16, 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f6f9f",
   "metadata": {},
   "source": [
    "## 6) Check Model Parameters\n",
    "View named parameters and total parameter count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93940f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for name, params in model.named_parameters():\n",
    "    num_params = int(torch.prod(torch.tensor(params.shape)))\n",
    "    print(name, \":\", params.shape, \"Num Parameters:\", num_params)\n",
    "    total_parameters += num_params\n",
    "\n",
    "print(\"-\" * 24)\n",
    "print(\"Total Parameters in Model\", total_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e248e",
   "metadata": {},
   "source": [
    "## 7) Training Utility\n",
    "Define a reusable train/validate loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5815f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, epochs, optimizer, loss_fn, trainloader, valloader):\n",
    "    log_training = {\n",
    "        \"epoch\": [],\n",
    "        \"training_loss\": [],\n",
    "        \"training_acc\": [],\n",
    "        \"validation_loss\": [],\n",
    "        \"validation_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        model.train()\n",
    "\n",
    "        training_losses, training_accuracies = [], []\n",
    "        validation_losses, validation_accuracies = [], []\n",
    "\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(image)\n",
    "\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            predictions = torch.argmax(out, dim=1)\n",
    "            accuracy = (predictions == label).float().mean()\n",
    "            training_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for image, label in tqdm(valloader):\n",
    "                image, label = image.to(device), label.to(device)\n",
    "                out = model(image)\n",
    "\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                predictions = torch.argmax(out, dim=1)\n",
    "                accuracy = (predictions == label).float().mean()\n",
    "                validation_accuracies.append(accuracy.item())\n",
    "\n",
    "        training_loss_mean = np.mean(training_losses)\n",
    "        training_acc_mean = np.mean(training_accuracies)\n",
    "        valid_loss_mean = np.mean(validation_losses)\n",
    "        valid_acc_mean = np.mean(validation_accuracies)\n",
    "\n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean)\n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "\n",
    "    return log_training, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4e54a",
   "metadata": {},
   "source": [
    "## 8) Train AlexNet From Scratch\n",
    "Random initialization, then full training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on Device {DEVICE}\")\n",
    "\n",
    "model = alexnet()\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "scratch_logs, scratch_model = train(\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69ac60",
   "metadata": {},
   "source": [
    "## 9) Load Pretrained AlexNet and Fine-Tune End-to-End\n",
    "Use ImageNet weights, replace classifier head, train all layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2422139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "epochs = 2\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "finetune_all_logs, finetune_all_model = train(\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3194dc1",
   "metadata": {},
   "source": [
    "## 10) Freeze All Layers Except Final Classifier\n",
    "Keep pretrained feature extractor fixed and train only `classifier[6]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ebe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier.6\" not in name:\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "# Quick check\n",
    "for name, param in model.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        print(name)\n",
    "        print(\"requires_grad:\", param.requires_grad)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b3b4a",
   "metadata": {},
   "source": [
    "## 11) Train Only Final Classifier Layer\n",
    "Optimizer updates only parameters with `requires_grad=True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "optimizer = optim.Adam(\n",
    "    params=[p for p in model.parameters() if p.requires_grad],\n",
    "    lr=0.0001,\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "head_only_logs, head_only_model = train(\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    epochs=epochs,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22c185",
   "metadata": {},
   "source": [
    "## 12) Summary\n",
    "- Transfer learning reuses pretrained knowledge for new tasks.\n",
    "- You can fine-tune all layers or only train the classifier head.\n",
    "- It usually reduces training time and improves results with less data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}